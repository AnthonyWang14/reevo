_target_: utils.llm_client.openai.OpenAIClient

# Using llama api. See the available models at https://docs.llama-api.com/quickstart#available-models
model: deepseek-chat
temperature: 1.0  # temperature for chat completion
api_key: ${oc.env:DEEPSEEK_API_KEY,null}
base_url: https://api.deepseek.com
